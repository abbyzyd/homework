{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://img.kaikeba.com/web/kkb_index/img_index_logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基础课第一部分（python）第六次作业  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各位同学，大家好!  欢迎各位开始学习我们的人工智能课程。  \n",
    "这门课程假设大家不具备机器学习和人工智能的知识，但是希望大家具备初级的Python编程能力。  \n",
    "这门课程结束后，希望大家掌握Python语言以及人工智能基础知识，对CV，NLP，RS领域有一定深入的理解与编程能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 如何提交作业\n",
    "有关代码的作业，在上课平台上提交，具体方式，见作业提交指南\n",
    "## 2. 作业截止时间\n",
    "作业能帮助你回顾课堂内容，你又可以通过作业进行代码实操。咱们可要认真、及时的完成作业哦！自布置作业起两周内提交，助教及时批改作业哦～逾期提交不批改。（特殊情况，请找班主任请假。）\n",
    "## 3. 完成以下问答和编程练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**理论部分**  \n",
    "无"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**编程实践部分**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 爬虫数据集筛选及保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************原始数据****************************************\n",
      "[('城市', '日期', '质量等级', 'AQI指数', '当天AQI排名', 'PM2.5', 'PM10', 'So2', 'No2', 'Co', 'O3'), ('杭州', '2019-01-01', '良', '73', '205', '53', '72', '8', '39', '0.90', '20'), ('杭州', '2019-01-02', '良', '90', '202', '66', '90', '9', '48', '0.95', '21'), ('杭州', '2019-01-03', '轻度污染', '126', '249', '95', '127', '8', '61', '1.26', '6'), ('杭州', '2019-01-04', '良', '79', '205', '58', '83', '7', '53', '1.39', '5'), ('杭州', '2019-01-05', '优', '31', '43', '21', '27', '6', '42', '1.18', '6'), ('杭州', '2019-01-06', '良', '55', '131', '38', '51', '7', '42', '1.67', '10'), ('杭州', '2019-01-07', '良', '55', '106', '38', '58', '8', '55', '1.25', '4'), ('杭州', '2019-01-08', '良', '64', '161', '45', '62', '8', '47', '1.04', '18'), ('杭州', '2019-01-09', '良', '66', '209', '47', '66', '9', '51', '1.06', '17'), ('杭州', '2019-01-10', '优', '36', '82', '22', '31', '7', '49', '0.82', '6'), ('杭州', '2019-01-11', '优', '26', '30', '15', '21', '7', '48', '0.92', '3'), ('杭州', '2019-01-12', '优', '39', '53', '26', '37', '7', '37', '1.12', '13'), ('杭州', '2019-01-13', '良', '84', '150', '62', '86', '9', '42', '1.17', '22'), ('杭州', '2019-01-14', '轻度污染', '120', '211', '90', '126', '8', '56', '1.42', '10'), ('杭州', '2019-01-15', '轻度污染', '102', '241', '76', '91', '8', '52', '1.37', '23'), ('杭州', '2019-01-16', '良', '84', '288', '60', '90', '9', '37', '0.99', '26'), ('杭州', '2019-01-17', '良', '81', '187', '59', '97', '9', '46', '0.99', '23'), ('杭州', '2019-01-18', '良', '91', '203', '66', '117', '8', '53', '1.12', '27'), ('杭州', '2019-01-19', '良', '92', '199', '68', '119', '7', '55', '1.26', '10'), ('杭州', '2019-01-20', '轻度污染', '150', '325', '114', '158', '11', '40', '1.30', '40'), ('杭州', '2019-01-21', '良', '73', '192', '52', '84', '9', '47', '0.83', '26'), ('杭州', '2019-01-22', '良', '92', '217', '68', '110', '8', '49', '1.00', '36'), ('杭州', '2019-01-23', '良', '95', '217', '70', '116', '8', '58', '1.10', '36'), ('杭州', '2019-01-24', '轻度污染', '118', '243', '88', '141', '10', '63', '1.10', '46'), ('杭州', '2019-01-25', '轻度污染', '143', '304', '107', '157', '10', '65', '1.06', '36'), ('杭州', '2019-01-26', '优', '49', '78', '28', '50', '7', '24', '0.66', '52'), ('杭州', '2019-01-27', '良', '60', '100', '38', '68', '6', '41', '0.74', '35'), ('杭州', '2019-01-28', '良', '92', '225', '67', '107', '10', '59', '0.98', '15'), ('杭州', '2019-01-29', '轻度污染', '133', '288', '100', '135', '8', '49', '1.03', '32'), ('杭州', '2019-01-30', '轻度污染', '127', '282', '96', '138', '9', '46', '1.06', '34'), ('杭州', '2019-01-31', '优', '39', '62', '22', '37', '5', '23', '0.71', '45')]\n",
      "******************************过滤数据(保留质量等级优 良 数据)******************************\n",
      "城市,日期,质量等级,AQI指数,当天AQI排名,PM2.5,PM10,So2,No2,Co,O3\n",
      "杭州,2019-01-01,良,73,205,53,72,8,39,0.90,20\n",
      "杭州,2019-01-02,良,90,202,66,90,9,48,0.95,21\n",
      "杭州,2019-01-04,良,79,205,58,83,7,53,1.39,5\n",
      "杭州,2019-01-05,优,31,43,21,27,6,42,1.18,6\n",
      "杭州,2019-01-06,良,55,131,38,51,7,42,1.67,10\n",
      "杭州,2019-01-07,良,55,106,38,58,8,55,1.25,4\n",
      "杭州,2019-01-08,良,64,161,45,62,8,47,1.04,18\n",
      "杭州,2019-01-09,良,66,209,47,66,9,51,1.06,17\n",
      "杭州,2019-01-10,优,36,82,22,31,7,49,0.82,6\n",
      "杭州,2019-01-11,优,26,30,15,21,7,48,0.92,3\n",
      "杭州,2019-01-12,优,39,53,26,37,7,37,1.12,13\n",
      "杭州,2019-01-13,良,84,150,62,86,9,42,1.17,22\n",
      "杭州,2019-01-16,良,84,288,60,90,9,37,0.99,26\n",
      "杭州,2019-01-17,良,81,187,59,97,9,46,0.99,23\n",
      "杭州,2019-01-18,良,91,203,66,117,8,53,1.12,27\n",
      "杭州,2019-01-19,良,92,199,68,119,7,55,1.26,10\n",
      "杭州,2019-01-21,良,73,192,52,84,9,47,0.83,26\n",
      "杭州,2019-01-22,良,92,217,68,110,8,49,1.00,36\n",
      "杭州,2019-01-23,良,95,217,70,116,8,58,1.10,36\n",
      "杭州,2019-01-26,优,49,78,28,50,7,24,0.66,52\n",
      "杭州,2019-01-27,良,60,100,38,68,6,41,0.74,35\n",
      "杭州,2019-01-28,良,92,225,67,107,10,59,0.98,15\n",
      "杭州,2019-01-31,优,39,62,22,37,5,23,0.71,45\n",
      "******************************data saved in ./data.txt******************************\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "# 以前遇到过的函数\n",
    "\n",
    "def build_url(city_coding, year=None, month=None):\n",
    "    \"\"\"\n",
    "    创建网页链接\n",
    "    paramters:\n",
    "        city_coding: 城市名称(英文)\n",
    "        year: 年份\n",
    "        month: 月份\n",
    "    return:\n",
    "        url: 可访问的链接\n",
    "    \"\"\"\n",
    "    BASE = 'http://www.tianqihoubao.com/aqi/'\n",
    "    city_base_url = BASE + '{}.html'\n",
    "    city_date_base_url = BASE + '{}-{}{}.html'\n",
    "    \n",
    "    if year is not None and month is not None:\n",
    "        month = str(month) if month >= 10 else '0' + str(month)\n",
    "        return city_date_base_url.format(city_coding, year, month)\n",
    "    else:\n",
    "        return city_base_url.format(city_coding)\n",
    "\n",
    "\n",
    "def parse(url, city_name):\n",
    "    \"\"\"\n",
    "    抓取网页信息\n",
    "    parameters:\n",
    "        url: 需要抓取的网页链接\n",
    "        city_name: 城市名称(用于数据标识)\n",
    "    returns:\n",
    "        result: 抓取的信息\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.ok:\n",
    "        html = response.text\n",
    "        \n",
    "        soup = BeautifulSoup(html)\n",
    "        data_table = soup.table\n",
    "        \n",
    "        content = data_table.contents\n",
    "        \n",
    "        result = []\n",
    "        for index, c in enumerate(content[1::2]):\n",
    "                if index == 0:\n",
    "                    result.append(tuple(['城市'] + c.text.split()))\n",
    "                else:\n",
    "                    result.append(tuple([city_name] + c.text.split()))\n",
    "        return result\n",
    "    \n",
    "    else:\n",
    "        if response.status_code == 403:\n",
    "            print('403 Forbidden! 抓取太快你被拉黑啦~')\n",
    "\n",
    "            \n",
    "def save(data, file):\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "    with open(file,'w') as f:\n",
    "            for item in data:\n",
    "                item_string=','.join(item)\n",
    "                print(item_string)\n",
    "                f.write(item_string+'\\n') # 添加换行符\n",
    "    # 完成数据保存到文件\n",
    "    # your code here\n",
    "    # 提示：用什么方法将数据写入文件？\n",
    "    \n",
    "    print('{0}data saved in {1}{0}'.format('*'*30,file))\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    datas = []\n",
    "    for i in range(1, 2):\n",
    "        url = build_url('hangzhou', 2019, i)\n",
    "        data = parse(url, '杭州')\n",
    "        datas.extend(data)\n",
    "    print('{0}原始数据{0}'.format('*'*40))\n",
    "    print(datas)\n",
    "    # 只保留质量等级优 良 数据\n",
    "    e = lambda item: item[2]=='优' or item[2]=='良' or item[2]=='质量等级'\n",
    "    filtered_data=list(filter(e, datas))\n",
    "    print('{0}过滤数据(保留质量等级优 良 数据){0}'.format('*'*30))\n",
    "    # 保存数据\n",
    "    save(filtered_data, './data.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 西瓜数据集保存及读取  \n",
    "添加编号列，并将数据集写入到`machine_learning.csv`文件，使用pandas读取验证文件是否有效(无错即可)。  \n",
    "添加一条记录，`青绿 硬挺 浊响 稍糊 平坦 硬滑 0.666 0.111 好`  \n",
    "再使用普通文件读取将数据集读取出来，列名读取到`columns`，数据(带编号)读取到`datalist`  \n",
    "在所有数据中过滤出色泽='浅白'的数据  \n",
    "在所有数据中过滤出密度大于0.5的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************将数据写入csv文件****************************************\n",
      "编号,色泽,根蒂,敲声,纹理,脐部,触感,密度,含糖率,好瓜\n",
      "1,青绿,蜷缩,浊响,清晰,凹陷,硬滑,0.697,0.460,是\n",
      "2,乌黑,蜷缩,沉闷,清晰,凹陷,硬滑,0.774,0.376,是\n",
      "3,乌黑,蜷缩,浊响,清晰,凹陷,硬滑,0.634,0.264,是\n",
      "4,青绿,蜷缩,沉闷,清晰,凹陷,硬滑,0.608,0.318,是\n",
      "5,浅白,蜷缩,浊响,清晰,凹陷,硬滑,0.556,0.215,是\n",
      "6,青绿,稍蜷,浊响,清晰,稍凹,软粘,0.403,0.237,是\n",
      "7,乌黑,稍蜷,浊响,稍糊,稍凹,软粘,0.481,0.149,是\n",
      "8,乌黑,稍蜷,浊响,清晰,稍凹,硬滑,0.437,0.211,是\n",
      "9,乌黑,稍蜷,沉闷,稍糊,稍凹,硬滑,0.666,0.091,否\n",
      "10,青绿,硬挺,清脆,清晰,平坦,软粘,0.243,0.267,否\n",
      "11,浅白,硬挺,清脆,模糊,平坦,硬滑,0.245,0.057,否\n",
      "12,浅白,蜷缩,浊响,模糊,平坦,软粘,0.343,0.099,否\n",
      "13,青绿,稍蜷,浊响,稍糊,凹陷,硬滑,0.639,0.161,否\n",
      "14,浅白,稍蜷,沉闷,稍糊,凹陷,硬滑,0.657,0.198,否\n",
      "15,乌黑,稍蜷,浊响,清晰,稍凹,软粘,0.360,0.370,否\n",
      "16,浅白,蜷缩,浊响,模糊,平坦,硬滑,0.593,0.042,否\n",
      "17,青绿,蜷缩,沉闷,稍糊,稍凹,硬滑,0.719,0.103,否\n",
      "\n",
      "****************************************向csv文件中加入一条新的数据****************************************\n",
      "\n",
      "****************************************查看全体数据****************************************\n",
      "    编号  色泽  根蒂  敲声  纹理  脐部  触感     密度    含糖率 好瓜\n",
      "0    1  青绿  蜷缩  浊响  清晰  凹陷  硬滑  0.697  0.460  是\n",
      "1    2  乌黑  蜷缩  沉闷  清晰  凹陷  硬滑  0.774  0.376  是\n",
      "2    3  乌黑  蜷缩  浊响  清晰  凹陷  硬滑  0.634  0.264  是\n",
      "3    4  青绿  蜷缩  沉闷  清晰  凹陷  硬滑  0.608  0.318  是\n",
      "4    5  浅白  蜷缩  浊响  清晰  凹陷  硬滑  0.556  0.215  是\n",
      "5    6  青绿  稍蜷  浊响  清晰  稍凹  软粘  0.403  0.237  是\n",
      "6    7  乌黑  稍蜷  浊响  稍糊  稍凹  软粘  0.481  0.149  是\n",
      "7    8  乌黑  稍蜷  浊响  清晰  稍凹  硬滑  0.437  0.211  是\n",
      "8    9  乌黑  稍蜷  沉闷  稍糊  稍凹  硬滑  0.666  0.091  否\n",
      "9   10  青绿  硬挺  清脆  清晰  平坦  软粘  0.243  0.267  否\n",
      "10  11  浅白  硬挺  清脆  模糊  平坦  硬滑  0.245  0.057  否\n",
      "11  12  浅白  蜷缩  浊响  模糊  平坦  软粘  0.343  0.099  否\n",
      "12  13  青绿  稍蜷  浊响  稍糊  凹陷  硬滑  0.639  0.161  否\n",
      "13  14  浅白  稍蜷  沉闷  稍糊  凹陷  硬滑  0.657  0.198  否\n",
      "14  15  乌黑  稍蜷  浊响  清晰  稍凹  软粘  0.360  0.370  否\n",
      "15  16  浅白  蜷缩  浊响  模糊  平坦  硬滑  0.593  0.042  否\n",
      "16  17  青绿  蜷缩  沉闷  稍糊  稍凹  硬滑  0.719  0.103  否\n",
      "17  18  青绿  硬挺  浊响  稍糊  平坦  硬滑  0.666  0.111  是\n",
      "\n",
      "****************************************验证数据信息是否相符****************************************\n",
      "读取到的列标签： ['编号', '色泽', '根蒂', '敲声', '纹理', '脐部', '触感', '密度', '含糖率', '好瓜']\n",
      "列标签是否相符: True\n",
      "读取到的最后一行数据： ['18', '青绿', '硬挺', '浊响', '稍糊', '平坦', '硬滑', '0.666', '0.111', '是']\n",
      "最后一行数据是否相符: True\n",
      "\n",
      "****************************************在所有数据中过滤出色泽='浅白'的数据****************************************\n",
      "    编号  色泽  根蒂  敲声  纹理  脐部  触感     密度    含糖率 好瓜\n",
      "4    5  浅白  蜷缩  浊响  清晰  凹陷  硬滑  0.556  0.215  是\n",
      "10  11  浅白  硬挺  清脆  模糊  平坦  硬滑  0.245  0.057  否\n",
      "11  12  浅白  蜷缩  浊响  模糊  平坦  软粘  0.343  0.099  否\n",
      "13  14  浅白  稍蜷  沉闷  稍糊  凹陷  硬滑  0.657  0.198  否\n",
      "15  16  浅白  蜷缩  浊响  模糊  平坦  硬滑  0.593  0.042  否\n",
      "\n",
      "****************************************在所有数据中过滤出密度大于0.5的数据****************************************\n",
      "    编号  色泽  根蒂  敲声  纹理  脐部  触感     密度    含糖率 好瓜\n",
      "0    1  青绿  蜷缩  浊响  清晰  凹陷  硬滑  0.697  0.460  是\n",
      "1    2  乌黑  蜷缩  沉闷  清晰  凹陷  硬滑  0.774  0.376  是\n",
      "2    3  乌黑  蜷缩  浊响  清晰  凹陷  硬滑  0.634  0.264  是\n",
      "3    4  青绿  蜷缩  沉闷  清晰  凹陷  硬滑  0.608  0.318  是\n",
      "4    5  浅白  蜷缩  浊响  清晰  凹陷  硬滑  0.556  0.215  是\n",
      "8    9  乌黑  稍蜷  沉闷  稍糊  稍凹  硬滑  0.666  0.091  否\n",
      "12  13  青绿  稍蜷  浊响  稍糊  凹陷  硬滑  0.639  0.161  否\n",
      "13  14  浅白  稍蜷  沉闷  稍糊  凹陷  硬滑  0.657  0.198  否\n",
      "15  16  浅白  蜷缩  浊响  模糊  平坦  硬滑  0.593  0.042  否\n",
      "16  17  青绿  蜷缩  沉闷  稍糊  稍凹  硬滑  0.719  0.103  否\n",
      "17  18  青绿  硬挺  浊响  稍糊  平坦  硬滑  0.666  0.111  是\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = \\\n",
    "\"\"\"色泽 根蒂 敲声 纹理 脐部 触感 密度 含糖率 好瓜\n",
    "青绿 蜷缩 浊响 清晰 凹陷 硬滑 0.697 0.460 是\n",
    "乌黑 蜷缩 沉闷 清晰 凹陷 硬滑 0.774 0.376 是\n",
    "乌黑 蜷缩 浊响 清晰 凹陷 硬滑 0.634 0.264 是\n",
    "青绿 蜷缩 沉闷 清晰 凹陷 硬滑 0.608 0.318 是\n",
    "浅白 蜷缩 浊响 清晰 凹陷 硬滑 0.556 0.215 是\n",
    "青绿 稍蜷 浊响 清晰 稍凹 软粘 0.403 0.237 是\n",
    "乌黑 稍蜷 浊响 稍糊 稍凹 软粘 0.481 0.149 是\n",
    "乌黑 稍蜷 浊响 清晰 稍凹 硬滑 0.437 0.211 是\n",
    "乌黑 稍蜷 沉闷 稍糊 稍凹 硬滑 0.666 0.091 否\n",
    "青绿 硬挺 清脆 清晰 平坦 软粘 0.243 0.267 否\n",
    "浅白 硬挺 清脆 模糊 平坦 硬滑 0.245 0.057 否\n",
    "浅白 蜷缩 浊响 模糊 平坦 软粘 0.343 0.099 否\n",
    "青绿 稍蜷 浊响 稍糊 凹陷 硬滑 0.639 0.161 否\n",
    "浅白 稍蜷 沉闷 稍糊 凹陷 硬滑 0.657 0.198 否\n",
    "乌黑 稍蜷 浊响 清晰 稍凹 软粘 0.360 0.370 否\n",
    "浅白 蜷缩 浊响 模糊 平坦 硬滑 0.593 0.042 否\n",
    "青绿 蜷缩 沉闷 稍糊 稍凹 硬滑 0.719 0.103 否\"\"\"\n",
    "\n",
    "# 将数据写入csv文件\n",
    "print('{0}将数据写入csv文件{0}'.format('*'*40))  \n",
    "file = r'machine_learning.csv' # 文件名称，学员可修改或不修改\n",
    "if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "list_data=dataset.split('\\n')\n",
    "for (i,item) in enumerate(list_data):\n",
    "    if i==0:\n",
    "        list_data[i]='编号 '+item\n",
    "    else:\n",
    "        list_data[i]=str(i)+' '+item\n",
    "\n",
    "new_dataset=(('\\n').join(list_data)).replace(' ',',')        \n",
    "print(new_dataset)\n",
    "with open(file,'w') as f:\n",
    "    f.write(new_dataset)\n",
    "#e = lambda item: item.split()\n",
    "#df=pd.DataFrame(columns=list_data[0].split(),data=list(map(e,list_data[1:])))\n",
    "#print(df)\n",
    "#df.to_csv(file,encoding='gbk')\n",
    "# 向csv文件中加入一条新的数据（数据已给出）\n",
    "# your code here\n",
    "# 注意每一行数据的间隔符号是什么\n",
    "print('\\n{0}向csv文件中加入一条新的数据{0}'.format('*'*40))  \n",
    "inser_data = '18 青绿 硬挺 浊响 稍糊 平坦 硬滑 0.666 0.111 是'\n",
    "inser_data = '\\n'+inser_data.replace(' ',',')\n",
    "with open(file,'a') as f:\n",
    "    f.write(inser_data)\n",
    "print('\\n{0}查看全体数据{0}'.format('*'*40))    \n",
    "# 查看全体数据\n",
    "df = pd.read_csv(file,encoding=\"GBK\")\n",
    "print(df)\n",
    "# 读取文件存储的数据\n",
    "# your code here\n",
    "# columns是指列标签\n",
    "# datalist指全体数据内容，每一行数据应为一个列表\n",
    "columns = list(df.columns.values)\n",
    "datalist = []\n",
    "\n",
    "# 验证数据信息是否相符\n",
    "print('\\n{0}验证数据信息是否相符{0}'.format('*'*40))\n",
    "print('读取到的列标签：',columns)\n",
    "print('列标签是否相符:',columns==['编号', '色泽', '根蒂', '敲声', '纹理', '脐部', '触感', '密度', '含糖率', '好瓜'])\n",
    "#df=df.loc[:,:]\n",
    "#print(df.tolist())\n",
    "for index, row in df.iterrows():\n",
    "    item=[]\n",
    "    for col in columns:\n",
    "        if col!='编号' and isinstance(row[col],(float,int)):\n",
    "            item.append('{:.3f}'.format(row[col]))\n",
    "        else:\n",
    "            item.append(str(row[col]).strip())\n",
    "    datalist.append(item)\n",
    "#print(datalist)\n",
    "print('读取到的最后一行数据：',datalist[-1])\n",
    "print('最后一行数据是否相符:',datalist[-1]==['18', '青绿', '硬挺', '浊响', '稍糊', '平坦', '硬滑', '0.666', '0.111', '是'])\n",
    "\n",
    "# 在所有数据中过滤出色泽='浅白'的数据\n",
    "print('\\n{0}在所有数据中过滤出色泽=\\'浅白\\'的数据{0}'.format('*'*40))\n",
    "#color_filter = lambda item: item[1]=='浅白'\n",
    "#color_filter_data=list(filter(color_filter, datalist))\n",
    "print(df.loc[df['色泽'] == '浅白'])\n",
    "\n",
    "# 在所有数据中过滤出密度大于0.5的数据\n",
    "print('\\n{0}在所有数据中过滤出密度大于0.5的数据{0}'.format('*'*40))\n",
    "#density_filter = lambda item: float(item[7])>0.5\n",
    "#density_filter_data=list(filter(density_filter, datalist))\n",
    "#print(density_filter_data)\n",
    "print(df.loc[df['密度'] >0.5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 评阅点：\n",
    "1. 使用,替代空格，并添加编号写入csv文件，可通过pandas进行验证  \n",
    "2. 使用a模式进行数据添加\n",
    "3. 读取数据文件并存到对应变量，注意strip，可根据最后验证代码进行验证  \n",
    "4. 使用filter lambda配合进行条件过滤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
